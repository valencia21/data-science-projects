{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a67cd5-fa3d-46eb-b305-05b743a8d4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0414 03:30:52.946936776    4131 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0414 03:30:52.960351721    4131 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0414 03:30:52.970095364    4131 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.2',\n",
       " 'raylet_ip_address': '172.17.0.2',\n",
       " 'redis_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2022-04-14_03-30-51_881425_4131/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-04-14_03-30-51_881425_4131/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-04-14_03-30-51_881425_4131',\n",
       " 'metrics_export_port': 46999,\n",
       " 'gcs_address': '172.17.0.2:52573',\n",
       " 'address': '172.17.0.2:52573',\n",
       " 'node_id': '38e4acfb537bf6a93aec07a49fd5f7a5aba72a1b53ab814b3be56c3d'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import ray\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4ea46a-ead9-4af4-8248-b9917bec1e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 03:30:56.937061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:56.987880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:56.988082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:56.988939: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-14 03:30:56.992460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:56.992706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:56.992854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:57.889246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:57.889477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:57.889487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-04-14 03:30:57.889660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-14 03:30:57.890067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tf_transactions = tf.data.experimental.load(\"tf_transactions\")\n",
    "tf_items = tf.data.experimental.load(\"tf_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31bbff47-e39c-4c3f-af0c-8bbde8e81ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transactions = tf_transactions.map(lambda x: {'customer_id' : x['customer_id'], \n",
    "                                            'product_code' : x['product_code'], \n",
    "                                            'quantity' : float(x['quantity']),})\n",
    "\n",
    "tf_items = tf_items.map(lambda x: x['product_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc40185-d589-455c-8bc9-3a04b413eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lookup table of unique items and customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ceaac5-458a-4ded-ba9a-c5d1fcd129b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_item_titles = np.unique(np.concatenate(list(tf_items.batch(1000))))\n",
    "unique_customer_ids = np.unique(np.concatenate(list(tf_transactions.batch(1_000).map(lambda x: x[\"customer_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7153047-b1a2-458a-b96e-501e795a4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lookup tables\n",
    "with open('unique_item_titles.pkl','wb') as handle:\n",
    "    pickle.dump(unique_item_titles, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('unique_customer_ids.pkl','wb') as handle:\n",
    "    pickle.dump(unique_customer_ids, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc509f82-203d-4f97-989a-1a46eb9ca3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset and split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a334f751-194a-41ba-bea6-9aa846bd00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(100)\n",
    "shuffled = tf_transactions.shuffle(100_000, seed=100, reshuffle_each_iteration=False)\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21229d51-38de-445a-bff4-c0dc492612bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24415302"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17c356d-b770-4e9e-b202-1d339d0199da",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2de68ca-6ddb-4bc6-97f0-fc041a54d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_customer_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb172ab0-7bfa-41b6-add6-877dcc2a5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_item_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113384da-41c7-4c9d-b545-60042a57e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "787393b5-3cf3-4e81-87f5-5d6941226e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=tf_items.batch(128).map(item_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d57ea571-c82a-4f7f-9b92-474c8be6d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02e2279a-deb3-4c30-b0f8-bc15b64e1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "class HMRecommenderModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    self.item_model: tf.keras.Model = item_model\n",
    "    self.customer_model: tf.keras.Model = customer_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the customer model.\n",
    "    customer_embeddings = self.customer_model(features[\"customer_id\"])\n",
    "    # And pick out the item features and pass them into the item model,\n",
    "    # getting embeddings back.\n",
    "    positive_item_embeddings = self.item_model(features[\"product_code\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(customer_embeddings, positive_item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f92d4ba-9058-4c82-ad68-31f2504e324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMRecommenderModel(customer_model, item_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6119dc5d-223c-4491-b548-0e5426237021",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54f14027-e66c-4bd9-89ff-00f6755e3243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 03:46:12.918880: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 60s 5s/step - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0030 - factorized_top_k/top_50_categorical_accuracy: 0.0104 - factorized_top_k/top_100_categorical_accuracy: 0.0166 - loss: 70366.7188 - regularization_loss: 0.0000e+00 - total_loss: 70366.7188\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 51s 5s/step - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0245 - factorized_top_k/top_10_categorical_accuracy: 0.0406 - factorized_top_k/top_50_categorical_accuracy: 0.1062 - factorized_top_k/top_100_categorical_accuracy: 0.1564 - loss: 69781.0000 - regularization_loss: 0.0000e+00 - total_loss: 69781.0000\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 52s 5s/step - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0700 - factorized_top_k/top_10_categorical_accuracy: 0.1035 - factorized_top_k/top_50_categorical_accuracy: 0.2211 - factorized_top_k/top_100_categorical_accuracy: 0.3032 - loss: 67049.1165 - regularization_loss: 0.0000e+00 - total_loss: 67049.1165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c3eda6a00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35ab8b78-8934-4d2a-8818-3ae583c353fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 18s 3s/step - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0082 - factorized_top_k/top_50_categorical_accuracy: 0.0290 - factorized_top_k/top_100_categorical_accuracy: 0.0481 - loss: 32705.2233 - regularization_loss: 0.0000e+00 - total_loss: 32705.2233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.00044999999227002263,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.003949999809265137,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.008200000040233135,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.028950000181794167,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.04805000126361847,\n",
       " 'loss': 29752.251953125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 29752.251953125}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96b782bf-a70e-4e01-a4b2-be46f848954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f0be47e8220>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.customer_model, k=12)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((tf_items.batch(100), tf_items.batch(100).map(model.item_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0a1068e-66db-4f59-b364-5cd1fd9c459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user: [[b'591334' b'568601' b'605094' b'859416' b'188183' b'590928' b'681373'\n",
      "  b'582480' b'179950' b'678260' b'745232' b'664074']]\n"
     ]
    }
   ],
   "source": [
    "_, items = index(tf.constant([\"00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657\"]))\n",
    "print(f\"Recommendations for user: {items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76c5f959-913b-47a6-bc69-5c54931aca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657',\n",
       "       b'0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa',\n",
       "       b'000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318',\n",
       "       ...,\n",
       "       b'ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1778d0116cffd259264',\n",
       "       b'ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38b2236865d949d4df6a',\n",
       "       b'ffffd9ac14e89946416d80e791d064701994755c3ab686a1eaf3458c36f52241'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_customer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004020ef-c6c7-4b7b-aa4e-7ae44f11ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into https://www.datarobot.com/jp/platform/mlops/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
