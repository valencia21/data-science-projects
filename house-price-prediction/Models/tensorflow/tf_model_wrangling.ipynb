{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9b44ee-21e3-44e1-ab3b-4af5c351aca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.losses import Huber\n",
    "from time import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f674b",
   "metadata": {},
   "source": [
    "In my previous post, I went through the following process:\n",
    "\n",
    "Environment: Anaconda, Windows 11.\n",
    "\n",
    "- Data wrangling (Light exploration, followed by removing and transforming some variables)\n",
    "- Split the training dataset into training and validation datasets\n",
    "- Fit a model using a Scikit-Learn pipeline (Data Preprocessing + fitting XGBoost/LightGBM estimators with a Randomized Search across their respective hyperparameters)\n",
    "- Evaluate and visualize model performance\n",
    "- Implement an automated approach to selecting hyperparameters (HyperOpt)\n",
    "- Make predictions\n",
    "\n",
    "In this post, I will implement the following using the same wrangled/preprocessed data:\n",
    "\n",
    "Environment: Docker, Windows Subsystem for Linux 2 (WSL 2), Windows 11.\n",
    "\n",
    "- Build a simple Sequential model in Keras/Tensorflow\n",
    "- Use the Weights and Biases (WandB) platform to select optimal hyperparameters and record experiments.\n",
    "  - Experiments are evaluated using K-Fold Cross Validation. Mean RMSE across folds for each experiment are custom logged in WandB. \n",
    "- Make predictions.\n",
    "- Blend predictions from the previous post (decision tree) and this post (neural net).\n",
    "  - By both taking the mean of predictions, and defining a meta-model trained on a holdout dataset kept completely separate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557fef8e",
   "metadata": {},
   "source": [
    "Actually setting up the environment (Docker, Windows Subsystem for Linux 2 (WSL 2), Windows 11, VSCode, using CUDA) took a couple of days and is probably worthy of its own blog post. It required the following process:\n",
    "\n",
    "- Install WSL2, CUDA drivers and Docker\n",
    "    - Define a Dockerfile that uses a base image compatible with CUDA\n",
    "    - Get libraries from requirements.txt\n",
    "    - Set \"runArgs\" in devcontainer.json to allow GPU usage\n",
    "- Run in VSCode (the Jupyter extension gave me some trouble)\n",
    "    - I ended up creating the container directly from a Dockerfile in the same repo as my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41683053-0452-48d6-8033-a5e2909e0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306/2886453018.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train = X_train.append(X_valid).reset_index().drop(columns=\"index\")\n",
      "/tmp/ipykernel_306/2886453018.py:24: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train = y_train.append(y_valid).reset_index().drop(columns=\"index\").values\n"
     ]
    }
   ],
   "source": [
    "# Function to bring in wrangled/preprocessed data from previous post\n",
    "def data():\n",
    "    training = pd.read_csv(\"../sklearn/training_preprocessed\")\n",
    "    validation = pd.read_csv(\"../sklearn/validation_preprocessed\")\n",
    "    holdout = pd.read_csv(\"../sklearn/holdout_preprocessed\")\n",
    "    holdout_predictions_df = pd.read_csv(\"../sklearn/holdout_preds_preprocessed\")\n",
    "    test = pd.read_csv(\"../sklearn/test_preprocessed\")\n",
    "    \n",
    "    X_train = training.drop(columns=\"SalePrice\")\n",
    "    y_train = training[\"SalePrice\"]\n",
    "    X_valid = validation.drop(columns=\"SalePrice\")\n",
    "    y_valid = validation[\"SalePrice\"]\n",
    "    X_holdout = holdout.drop(columns=\"Actual_SalePrice\")\n",
    "    y_holdout = holdout[\"Actual_SalePrice\"]\n",
    "    X_test = test\n",
    "    holdout_predictions_df = holdout_predictions_df\n",
    "    return X_train, y_train, X_valid, y_valid, X_holdout, y_holdout, X_test, holdout_predictions_df\n",
    "\n",
    "# Bring in data\n",
    "X_train, y_train, X_valid, y_valid, X_holdout, y_holdout, X_test, holdout_predictions_df = data()\n",
    "\n",
    "# Since this model uses k-fold validation, we don't need separate training and validation datasets\n",
    "X_train = X_train.append(X_valid).reset_index().drop(columns=\"index\")\n",
    "y_train = y_train.append(y_valid).reset_index().drop(columns=\"index\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd95926-a2d1-484d-8674-273e1310e88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluiscostigan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/wandb/run-20220309_042326-1f5fw31l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/luiscostigan/house-price-prediction/runs/1f5fw31l\" target=\"_blank\">desert-resonance-340</a></strong> to <a href=\"https://wandb.ai/luiscostigan/house-price-prediction\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/luiscostigan/house-price-prediction/runs/1f5fw31l?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f85b696e910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log into Weights and Biases\n",
    "wandb.init(project=\"house-price-prediction\", entity=\"luiscostigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06efad-42f3-4cb3-90c9-ee188ed47acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple Sequential model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(wandb.config.dense1, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(wandb.config.dropout1))\n",
    "    model.add(Dense(wandb.config.dense2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss=Huber(), metrics=[RootMeanSquaredError()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e707d3f-2deb-4ac1-b274-48350e1027bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function and hyperparameter ranges\n",
    "from wandb.keras import WandbCallback\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sweep_config = {\n",
    "  \"name\": \"keras-sequential-model-sweep\",\n",
    "  \"method\": \"random\",\n",
    "  \"parameters\": {\n",
    "    \"dropout1\": {\n",
    "      \"min\": 0.0,\n",
    "      \"max\": 0.4\n",
    "    },\n",
    "    \"dense1\": {\n",
    "      \"values\": [32, 128, 512, 2048]\n",
    "    },\n",
    "    \"dense2\": {\n",
    "      \"values\": [32, 128, 512, 2048]\n",
    "    },\n",
    "    \"epochs\": {\n",
    "      \"values\": [30, 100, 250]\n",
    "    },\n",
    "    \"batch_size\": {\n",
    "      \"values\": [16, 32, 64]\n",
    "    }\n",
    "  },\n",
    "  \"metric\": {\n",
    "    \"name\": \"Mean Validation RMSE (all folds)\",\n",
    "    \"goal\": \"minimize\"\n",
    "  }\n",
    "}\n",
    "\n",
    "config_defaults = {\n",
    "  \"dropout1\": 0.1,\n",
    "  \"dense1\": 512,\n",
    "  \"dense2\": 512,\n",
    "  \"epochs\": 100,\n",
    "  \"batch_size\": 32\n",
    "}\n",
    "\n",
    "# Define number of splits\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "def train():\n",
    "\n",
    "  rmse_per_fold = []\n",
    "  loss_per_fold = []\n",
    "  fold_no = 1\n",
    "\n",
    "  # Go through each split, and get the index number for each\n",
    "  for train, test in kf.split(X_train, y_train):\n",
    "\n",
    "    # With the current session in WandB\n",
    "    with wandb.init(config=config_defaults) as run:\n",
    "\n",
    "      # Recreate the model each time for each new batch\n",
    "      model = None # Not sure if this step is necessary\n",
    "      model = create_model()\n",
    "\n",
    "      # Fit model on new batches\n",
    "      model.fit(\n",
    "        np.asarray(X_train), \n",
    "        y_train, \n",
    "        epochs=wandb.config.epochs, \n",
    "        batch_size=wandb.config.batch_size, \n",
    "        verbose=0,\n",
    "        callbacks=[WandbCallback()], \n",
    "        validation_data=(np.asarray(X_train),y_train)\n",
    "        )\n",
    "      \n",
    "      # Generate data for each\n",
    "      scores = model.evaluate(np.asarray(X_train), y_train, callbacks=[WandbCallback()])\n",
    "      print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
    "      rmse_per_fold.append(scores[1])\n",
    "      loss_per_fold.append(scores[0])\n",
    "\n",
    "      # Increase fold number\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "      # == Provide average scores ==\n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(rmse_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - RMSE: {rmse_per_fold[i]}')\n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Average scores for all folds:')\n",
    "      print(f'> RMSE: {np.mean(rmse_per_fold)} (+- {np.std(rmse_per_fold)})')\n",
    "      print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "      print('------------------------------------------------------------------------')\n",
    "\n",
    "      wandb.log({\n",
    "        \"Mean Validation RMSE (all folds)\": np.mean(rmse_per_fold),\n",
    "        \"Mean Validation Loss (all folds)\": np.mean(loss_per_fold) \n",
    "        })\n",
    "\n",
    "      wandb.join()\n",
    "\n",
    "keras_sequential_sweep_1 = wandb.sweep(sweep_config, project=\"house-price-prediction\", entity=\"luiscostigan\")\n",
    "\n",
    "count = 10\n",
    "\n",
    "wandb.agent(keras_sequential_sweep_1, function=train, count=count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa74eb",
   "metadata": {},
   "source": [
    "Hyperparameter optimization and experiment recording all took place within the Weights and Biases platform. The set of hyperparameters resulting in the lowest loss (in terms of RMSE) is noted in the top row of the image below:\n",
    "\n",
    "<img src=\"./wandb_rmse.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7b238b8d-bf25-43da-acdb-7caa72dec5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter best params from sweep\n",
    "best_params = {\n",
    "    \"dropout\": 0.05,\n",
    "    \"dense1\": 8192,\n",
    "    \"dense2\": 8192,\n",
    "    \"dense3\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 2\n",
    "}\n",
    "\n",
    "# Build model using the best parameters\n",
    "def make_predictions(best_params, dataset):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_params.get(\"dense1\"), input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(best_params.get(\"dropout\")))\n",
    "    model.add(Dense(best_params.get(\"dense2\"), activation='relu'))\n",
    "    model.add(Dense(best_params.get(\"dense3\"), activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.001), loss=\"mean_absolute_error\", metrics=[RootMeanSquaredError()])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=best_params.get(\"epochs\"), batch_size=best_params.get(\"batch_size\"), verbose = 0)\n",
    "                \n",
    "    preds  = model.predict(dataset, best_params.get(\"batch_size\"), verbose = 0)\n",
    "              \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "73e3b4ec-1072-44a8-82b7-620ce29e29db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 11:27:34.064532: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 256.00MiB (rounded to 268435456)requested by op RandomUniform\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-03-09 11:27:34.065038: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-03-09 11:27:34.065105: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 86, Chunks in use: 86. 21.5KiB allocated for chunks. 21.5KiB in use in bin. 420B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065126: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065132: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065136: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 2, Chunks in use: 1. 7.5KiB allocated for chunks. 3.8KiB in use in bin. 3.6KiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065139: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 6.8KiB allocated for chunks. 6.8KiB in use in bin. 3.6KiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065142: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065145: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 19.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065149: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 23, Chunks in use: 23. 743.8KiB allocated for chunks. 743.8KiB in use in bin. 736.0KiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065153: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065156: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065159: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0. 277.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065162: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 2, Chunks in use: 0. 1.65MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065164: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065167: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 2. 7.94MiB allocated for chunks. 4.46MiB in use in bin. 4.46MiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065170: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065174: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 11, Chunks in use: 9. 107.59MiB allocated for chunks. 88.03MiB in use in bin. 88.03MiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065177: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 2. 34.66MiB allocated for chunks. 34.66MiB in use in bin. 19.56MiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065181: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 32.20MiB allocated for chunks. 32.20MiB in use in bin. 19.56MiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065183: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065188: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 198.20MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065191: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 9, Chunks in use: 9. 3.00GiB allocated for chunks. 3.00GiB in use in bin. 3.00GiB client-requested in use in bin.\n",
      "2022-03-09 11:27:34.065241: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 256.00MiB was 256.00MiB, Chunk State: \n",
      "2022-03-09 11:27:34.065247: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 3623223296\n",
      "2022-03-09 11:27:34.065523: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700000 of size 256 next 1\n",
      "2022-03-09 11:27:34.065537: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700100 of size 1280 next 2\n",
      "2022-03-09 11:27:34.065541: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700600 of size 256 next 3\n",
      "2022-03-09 11:27:34.065544: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700700 of size 256 next 4\n",
      "2022-03-09 11:27:34.065546: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700800 of size 256 next 5\n",
      "2022-03-09 11:27:34.065549: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700900 of size 256 next 111\n",
      "2022-03-09 11:27:34.065552: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700a00 of size 256 next 70\n",
      "2022-03-09 11:27:34.065554: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700b00 of size 256 next 242\n",
      "2022-03-09 11:27:34.065557: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700c00 of size 256 next 179\n",
      "2022-03-09 11:27:34.065559: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700d00 of size 256 next 191\n",
      "2022-03-09 11:27:34.065561: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700e00 of size 256 next 105\n",
      "2022-03-09 11:27:34.065563: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610700f00 of size 256 next 189\n",
      "2022-03-09 11:27:34.065565: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701000 of size 256 next 6\n",
      "2022-03-09 11:27:34.065567: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701100 of size 256 next 9\n",
      "2022-03-09 11:27:34.065569: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701200 of size 256 next 10\n",
      "2022-03-09 11:27:34.065572: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701300 of size 256 next 57\n",
      "2022-03-09 11:27:34.065574: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701400 of size 256 next 83\n",
      "2022-03-09 11:27:34.065576: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701500 of size 256 next 85\n",
      "2022-03-09 11:27:34.065579: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610701600 of size 65536 next 92\n",
      "2022-03-09 11:27:34.065581: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610711600 of size 32768 next 51\n",
      "2022-03-09 11:27:34.065586: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610719600 of size 32768 next 16\n",
      "2022-03-09 11:27:34.065589: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610721600 of size 32768 next 126\n",
      "2022-03-09 11:27:34.065593: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610729600 of size 32768 next 64\n",
      "2022-03-09 11:27:34.065595: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 610731600 of size 283904 next 45\n",
      "2022-03-09 11:27:34.065610: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610776b00 of size 256 next 95\n",
      "2022-03-09 11:27:34.065615: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610776c00 of size 6912 next 37\n",
      "2022-03-09 11:27:34.065625: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610778700 of size 256 next 71\n",
      "2022-03-09 11:27:34.065628: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610778800 of size 32768 next 118\n",
      "2022-03-09 11:27:34.065631: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610780800 of size 32768 next 211\n",
      "2022-03-09 11:27:34.065633: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610788800 of size 32768 next 213\n",
      "2022-03-09 11:27:34.065635: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610790800 of size 32768 next 209\n",
      "2022-03-09 11:27:34.065638: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610798800 of size 32768 next 162\n",
      "2022-03-09 11:27:34.065640: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107a0800 of size 32768 next 48\n",
      "2022-03-09 11:27:34.065642: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107a8800 of size 32768 next 113\n",
      "2022-03-09 11:27:34.065645: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107b0800 of size 32768 next 150\n",
      "2022-03-09 11:27:34.065647: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107b8800 of size 36352 next 11\n",
      "2022-03-09 11:27:34.065649: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1600 of size 256 next 12\n",
      "2022-03-09 11:27:34.065651: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1700 of size 256 next 15\n",
      "2022-03-09 11:27:34.065654: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1800 of size 256 next 91\n",
      "2022-03-09 11:27:34.065656: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1900 of size 256 next 84\n",
      "2022-03-09 11:27:34.065658: I ten"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8192,8192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m test_predictions_log_transformed \u001b[39m=\u001b[39m make_predictions(best_params, X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m holdout_predictions_log_transformed \u001b[39m=\u001b[39m make_predictions(best_params, X_holdout)\n",
      "\u001b[1;32m/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb Cell 9'\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(best_params, dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000009vscode-remote?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(best_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdense1\u001b[39m\u001b[39m\"\u001b[39m), input_dim\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000009vscode-remote?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dropout(best_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000009vscode-remote?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49madd(Dense(best_params\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mdense2\u001b[39;49m\u001b[39m\"\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000009vscode-remote?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(best_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdense3\u001b[39m\u001b[39m\"\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c6c7569735f5c446f63756d656e74735c4769744875625c646174612d736369656e63652d70726f6a656374735c686f7573652d70726963652d70726564696374696f6e/workspaces/data-science-projects/house-price-prediction/Models/tensorflow/tf_model_wrangling.ipynb#ch0000009vscode-remote?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py?line=626'>627</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py?line=627'>628</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py?line=628'>629</a>\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py?line=629'>630</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py?line=630'>631</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py:1920\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/backend.py?line=1916'>1917</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/backend.py?line=1917'>1918</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/backend.py?line=1918'>1919</a>\u001b[0m       shape\u001b[39m=\u001b[39mshape, minval\u001b[39m=\u001b[39mminval, maxval\u001b[39m=\u001b[39mmaxval, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/backend.py?line=1919'>1920</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/backend.py?line=1920'>1921</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mshape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/backend.py?line=1921'>1922</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_legacy_seed())\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8192,8192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1a00 of size 256 next 65\n",
      "2022-03-09 11:27:34.065660: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1b00 of size 256 next 89\n",
      "2022-03-09 11:27:34.065662: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1c00 of size 256 next 88\n",
      "2022-03-09 11:27:34.065665: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1d00 of size 256 next 33\n",
      "2022-03-09 11:27:34.065667: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1e00 of size 256 next 19\n",
      "2022-03-09 11:27:34.065669: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c1f00 of size 256 next 22\n",
      "2022-03-09 11:27:34.065671: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2000 of size 256 next 80\n",
      "2022-03-09 11:27:34.065673: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2100 of size 256 next 82\n",
      "2022-03-09 11:27:34.065676: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2200 of size 256 next 63\n",
      "2022-03-09 11:27:34.065678: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2300 of size 256 next 77\n",
      "2022-03-09 11:27:34.065680: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2400 of size 256 next 66\n",
      "2022-03-09 11:27:34.065682: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2500 of size 256 next 100\n",
      "2022-03-09 11:27:34.065684: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2600 of size 256 next 69\n",
      "2022-03-09 11:27:34.065686: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2700 of size 256 next 112\n",
      "2022-03-09 11:27:34.065689: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2800 of size 256 next 110\n",
      "2022-03-09 11:27:34.065692: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2900 of size 256 next 98\n",
      "2022-03-09 11:27:34.065695: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2a00 of size 256 next 197\n",
      "2022-03-09 11:27:34.065697: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2b00 of size 256 next 141\n",
      "2022-03-09 11:27:34.065721: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2c00 of size 256 next 199\n",
      "2022-03-09 11:27:34.065724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2d00 of size 256 next 120\n",
      "2022-03-09 11:27:34.065727: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2e00 of size 256 next 99\n",
      "2022-03-09 11:27:34.065729: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c2f00 of size 256 next 114\n",
      "2022-03-09 11:27:34.065731: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3000 of size 256 next 248\n",
      "2022-03-09 11:27:34.065733: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3100 of size 256 next 212\n",
      "2022-03-09 11:27:34.065735: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3200 of size 256 next 23\n",
      "2022-03-09 11:27:34.065738: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3300 of size 256 next 24\n",
      "2022-03-09 11:27:34.065740: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3400 of size 256 next 26\n",
      "2022-03-09 11:27:34.065742: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3500 of size 256 next 27\n",
      "2022-03-09 11:27:34.065744: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3600 of size 256 next 28\n",
      "2022-03-09 11:27:34.065746: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3700 of size 256 next 29\n",
      "2022-03-09 11:27:34.065748: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3800 of size 256 next 30\n",
      "2022-03-09 11:27:34.065751: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6107c3900 of size 256 next 31\n",
      "2022-03-09 11:27:34.065753: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6107c3a00 of size 731392 next 143\n",
      "2022-03-09 11:27:34.065756: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610876300 of size 256 next 20\n",
      "2022-03-09 11:27:34.065759: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610876400 of size 32768 next 8\n",
      "2022-03-09 11:27:34.065762: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 61087e400 of size 32768 next 17\n",
      "2022-03-09 11:27:34.065808: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610886400 of size 32768 next 109\n",
      "2022-03-09 11:27:34.065811: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 61088e400 of size 32768 next 42\n",
      "2022-03-09 11:27:34.065814: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 610896400 of size 32768 next 52\n",
      "2022-03-09 11:27:34.065816: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 61089e400 of size 35328 next 166\n",
      "2022-03-09 11:27:34.065818: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6108a6e00 of size 32768 next 78\n",
      "2022-03-09 11:27:34.065821: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6108aee00 of size 1002496 next 174\n",
      "2022-03-09 11:27:34.065823: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109a3a00 of size 256 next 144\n",
      "2022-03-09 11:27:34.065825: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109a3b00 of size 32768 next 49\n",
      "2022-03-09 11:27:34.065827: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109abb00 of size 34560 next 192\n",
      "2022-03-09 11:27:34.065830: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b4200 of size 256 next 186\n",
      "2022-03-09 11:27:34.065832: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b4300 of size 256 next 81\n",
      "2022-03-09 11:27:34.065834: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b4400 of size 3840 next 247\n",
      "2022-03-09 11:27:34.065836: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5300 of size 256 next 210\n",
      "2022-03-09 11:27:34.065838: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5400 of size 256 next 115\n",
      "2022-03-09 11:27:34.065840: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5500 of size 256 next 230\n",
      "2022-03-09 11:27:34.065843: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5600 of size 256 next 107\n",
      "2022-03-09 11:27:34.065846: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5700 of size 256 next 108\n",
      "2022-03-09 11:27:34.065848: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5800 of size 256 next 125\n",
      "2022-03-09 11:27:34.065850: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5900 of size 256 next 61\n",
      "2022-03-09 11:27:34.065853: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5a00 of size 256 next 124\n",
      "2022-03-09 11:27:34.065855: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5b00 of size 256 next 154\n",
      "2022-03-09 11:27:34.065858: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5c00 of size 256 next 262\n",
      "2022-03-09 11:27:34.065860: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5d00 of size 256 next 43\n",
      "2022-03-09 11:27:34.065862: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5e00 of size 256 next 275\n",
      "2022-03-09 11:27:34.065865: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b5f00 of size 256 next 39\n",
      "2022-03-09 11:27:34.065868: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b6000 of size 256 next 13\n",
      "2022-03-09 11:27:34.065870: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b6100 of size 256 next 164\n",
      "2022-03-09 11:27:34.065872: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b6200 of size 256 next 172\n",
      "2022-03-09 11:27:34.065875: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b6300 of size 256 next 244\n",
      "2022-03-09 11:27:34.065877: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b6400 of size 256 next 41\n",
      "2022-03-09 11:27:34.065880: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6109b6500 of size 3840 next 14\n",
      "2022-03-09 11:27:34.065882: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b7400 of size 256 next 58\n",
      "2022-03-09 11:27:34.065884: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b7500 of size 256 next 277\n",
      "2022-03-09 11:27:34.065886: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b7600 of size 256 next 18\n",
      "2022-03-09 11:27:34.065888: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b7700 of size 256 next 25\n",
      "2022-03-09 11:27:34.065890: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109b7800 of size 256 next 53\n",
      "2022-03-09 11:27:34.065893: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6109b7900 of size 19456 next 184\n",
      "2022-03-09 11:27:34.065895: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109bc500 of size 256 next 188\n",
      "2022-03-09 11:27:34.065897: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109bc600 of size 256 next 180\n",
      "2022-03-09 11:27:34.065900: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109bc700 of size 32768 next 187\n",
      "2022-03-09 11:27:34.065902: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109c4700 of size 256 next 177\n",
      "2022-03-09 11:27:34.065904: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109c4800 of size 256 next 181\n",
      "2022-03-09 11:27:34.065906: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6109c4900 of size 268435456 next 38\n",
      "2022-03-09 11:27:34.065909: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6209c4900 of size 268435456 next 97\n",
      "2022-03-09 11:27:34.065911: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6309c4900 of size 268435456 next 102\n",
      "2022-03-09 11:27:34.065913: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6409c4900 of size 268435456 next 246\n",
      "2022-03-09 11:27:34.065915: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6509c4900 of size 268435456 next 167\n",
      "2022-03-09 11:27:34.065918: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6609c4900 of size 268435456 next 245\n",
      "2022-03-09 11:27:34.065920: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6709c4900 of size 1073741824 next 235\n",
      "2022-03-09 11:27:34.065922: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6b09c4900 of size 268435456 next 79\n",
      "2022-03-09 11:27:34.065924: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6c09c4900 of size 268435456 next 278\n",
      "2022-03-09 11:27:34.065928: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6d09c4900 of size 10256384 next 140\n",
      "2022-03-09 11:27:34.065931: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6d138c900 of size 10256384 next 123\n",
      "2022-03-09 11:27:34.065933: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6d1d54900 of size 207830784 next 135\n",
      "2022-03-09 11:27:34.065935: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6de388800 of size 10256384 next 136\n",
      "2022-03-09 11:27:34.065938: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6ded50800 of size 2338816 next 90\n",
      "2022-03-09 11:27:34.065940: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6def8b800 of size 18173952 next 96\n",
      "2022-03-09 11:27:34.065942: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e00e0800 of size 10256384 next 36\n",
      "2022-03-09 11:27:34.065945: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e0aa8800 of size 10256384 next 56\n",
      "2022-03-09 11:27:34.065947: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6e1470800 of size 3653376 next 130\n",
      "2022-03-09 11:27:34.065949: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e17ec700 of size 2338816 next 128\n",
      "2022-03-09 11:27:34.065951: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e1a27700 of size 18173952 next 7\n",
      "2022-03-09 11:27:34.065953: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e2b7c700 of size 10256384 next 93\n",
      "2022-03-09 11:27:34.065955: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e3544700 of size 10256384 next 249\n",
      "2022-03-09 11:27:34.065957: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6e3f0c700 of size 10256384 next 138\n",
      "2022-03-09 11:27:34.065960: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e48d4700 of size 10256384 next 74\n",
      "2022-03-09 11:27:34.065962: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e529c700 of size 10256384 next 132\n",
      "2022-03-09 11:27:34.065964: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 6e5c64700 of size 10256384 next 194\n",
      "2022-03-09 11:27:34.065967: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 6e662c700 of size 33765632 next 18446744073709551615\n",
      "2022-03-09 11:27:34.065969: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-03-09 11:27:34.065975: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 86 Chunks of size 256 totalling 21.5KiB\n",
      "2022-03-09 11:27:34.065978: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-03-09 11:27:34.065981: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2022-03-09 11:27:34.065984: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 6912 totalling 6.8KiB\n",
      "2022-03-09 11:27:34.065987: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 20 Chunks of size 32768 totalling 640.0KiB\n",
      "2022-03-09 11:27:34.065990: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 34560 totalling 33.8KiB\n",
      "2022-03-09 11:27:34.065992: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 35328 totalling 34.5KiB\n",
      "2022-03-09 11:27:34.066022: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 36352 totalling 35.5KiB\n",
      "2022-03-09 11:27:34.066044: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 65536 totalling 64.0KiB\n",
      "2022-03-09 11:27:34.066048: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 2338816 totalling 4.46MiB\n",
      "2022-03-09 11:27:34.066051: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 9 Chunks of size 10256384 totalling 88.03MiB\n",
      "2022-03-09 11:27:34.066054: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 18173952 totalling 34.66MiB\n",
      "2022-03-09 11:27:34.066056: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 33765632 totalling 32.20MiB\n",
      "2022-03-09 11:27:34.066059: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 8 Chunks of size 268435456 totalling 2.00GiB\n",
      "2022-03-09 11:27:34.066061: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1073741824 totalling 1.00GiB\n",
      "2022-03-09 11:27:34.066064: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 3.16GiB\n",
      "2022-03-09 11:27:34.066066: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 3623223296 memory_limit_: 3623223296 available bytes: 0 curr_region_allocation_bytes_: 7246446592\n",
      "2022-03-09 11:27:34.066142: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                      3623223296\n",
      "InUse:                      3389185280\n",
      "MaxInUse:                   3462116096\n",
      "NumAllocs:                     3353588\n",
      "MaxAllocSize:               1073741824\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-03-09 11:27:34.066171: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ******************************************************************************************_____*****\n",
      "2022-03-09 11:27:34.066717: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[8192,8192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_predictions_log_transformed = make_predictions(best_params, X_test)\n",
    "holdout_predictions_log_transformed = make_predictions(best_params, X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "444e0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo the log transform\n",
    "test_predictions = np.exp(test_predictions_log_transformed)\n",
    "holdout_predictions = np.exp(holdout_predictions_log_transformed)\n",
    "\n",
    "# Generating submission CSV\n",
    "d = {\"Id\":X_test.index,\"SalePrice\":test_predictions.flatten()}\n",
    "submission = pd.DataFrame(data=d, index=None)\n",
    "\n",
    "submission[\"Id\"] = submission[\"Id\"] + 1461\n",
    "\n",
    "submission.to_csv(\"submission_nn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb0b31",
   "metadata": {},
   "source": [
    "## Blending Predictions\n",
    "\n",
    "So far, I have generated predictions using a decision tree-based model and a neural net-based model.\n",
    "First, I'll try taking the mean of predictions from both to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "578a0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "decision_tree_predictions = pd.read_csv(\"../sklearn/xgb_lgb_test_predictions.csv\")\n",
    "neural_net_predictions = pd.read_csv(\"../tensorflow/submission_nn.csv\")\n",
    "\n",
    "# Merge CSVs on Id column\n",
    "decision_tree_predictions[\"NN_Predictions\"] = neural_net_predictions[\"SalePrice\"]\n",
    "\n",
    "# Log transform NN predictions again (for consistent RMSE value)\n",
    "decision_tree_predictions[\"NN_Predictions\"] = np.log(decision_tree_predictions[\"NN_Predictions\"])\n",
    "\n",
    "# Add new column with mean\n",
    "decision_tree_predictions[\"SalePrice\"] = decision_tree_predictions[[\"NN_Predictions\",\"XGBoost_Predictions\",\"LightGBM_Predictions\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d4109da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17502633791854189\n",
      "0.3557935296772313\n"
     ]
    }
   ],
   "source": [
    "# Refresh data\n",
    "X_train, y_train, X_valid, y_valid, X_holdout, y_holdout, X_test, holdout_predictions_df = data()\n",
    "\n",
    "# Append holdout set NN predictions to DT predictions\n",
    "holdout_predictions_df[\"NN_Predictions\"] = holdout_predictions_log_transformed\n",
    "holdout_predictions_df = holdout_predictions_df[[\"XGBoost_Predictions\", \"LightGBM_Predictions\", \"NN_Predictions\", \"Actual_SalePrice\"]]\n",
    "\n",
    "# Add mean column\n",
    "holdout_predictions_df[\"Mean_SalePrice\"] = holdout_predictions_df[[\"XGBoost_Predictions\", \"LightGBM_Predictions\", \"NN_Predictions\"]].mean(axis=1)\n",
    "\n",
    "# Add weighted mean column\n",
    "weight = [0, 0, 1]\n",
    "holdout_predictions_df[\"Weighted_Mean_SalePrice\"] = holdout_predictions_df[[\"XGBoost_Predictions\", \"LightGBM_Predictions\", \"NN_Predictions\"]].dot(weight)\n",
    "\n",
    "# Calculate RMSE\n",
    "print(mean_squared_error(holdout_predictions_df[\"Actual_SalePrice\"], holdout_predictions_df[\"Mean_SalePrice\"], squared=False))\n",
    "print(mean_squared_error(holdout_predictions_df[\"Actual_SalePrice\"], holdout_predictions_df[\"Weighted_Mean_SalePrice\"], squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "264327c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost_Predictions</th>\n",
       "      <th>LightGBM_Predictions</th>\n",
       "      <th>NN_Predictions</th>\n",
       "      <th>Actual_SalePrice</th>\n",
       "      <th>Mean_SalePrice</th>\n",
       "      <th>Weighted_Mean_SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193813.764467</td>\n",
       "      <td>208400.892259</td>\n",
       "      <td>157616.975689</td>\n",
       "      <td>208500.0</td>\n",
       "      <td>185337.112998</td>\n",
       "      <td>194026.451664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132119.883800</td>\n",
       "      <td>138532.076216</td>\n",
       "      <td>118430.910673</td>\n",
       "      <td>129500.0</td>\n",
       "      <td>129417.954594</td>\n",
       "      <td>132553.902928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128478.197544</td>\n",
       "      <td>149772.500875</td>\n",
       "      <td>98025.493775</td>\n",
       "      <td>132000.0</td>\n",
       "      <td>123556.856848</td>\n",
       "      <td>130936.639170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112995.017070</td>\n",
       "      <td>116435.661968</td>\n",
       "      <td>97396.407900</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>108616.569688</td>\n",
       "      <td>112335.151209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153034.168657</td>\n",
       "      <td>153558.656517</td>\n",
       "      <td>111143.027711</td>\n",
       "      <td>159000.0</td>\n",
       "      <td>137715.126478</td>\n",
       "      <td>148369.132926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>263619.749227</td>\n",
       "      <td>246863.530560</td>\n",
       "      <td>193733.388149</td>\n",
       "      <td>271000.0</td>\n",
       "      <td>232744.691390</td>\n",
       "      <td>250636.486400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>180573.107057</td>\n",
       "      <td>170542.417567</td>\n",
       "      <td>137372.957888</td>\n",
       "      <td>192140.0</td>\n",
       "      <td>161731.858998</td>\n",
       "      <td>172715.650256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>132455.762402</td>\n",
       "      <td>139596.575508</td>\n",
       "      <td>106045.326993</td>\n",
       "      <td>143750.0</td>\n",
       "      <td>125163.890023</td>\n",
       "      <td>131599.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>108509.824907</td>\n",
       "      <td>112157.994953</td>\n",
       "      <td>102181.881757</td>\n",
       "      <td>64500.0</td>\n",
       "      <td>107536.954265</td>\n",
       "      <td>108935.115520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>283112.889525</td>\n",
       "      <td>234790.182070</td>\n",
       "      <td>189229.858057</td>\n",
       "      <td>287090.0</td>\n",
       "      <td>232564.316481</td>\n",
       "      <td>257086.180190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     XGBoost_Predictions  LightGBM_Predictions  NN_Predictions  \\\n",
       "0          193813.764467         208400.892259   157616.975689   \n",
       "1          132119.883800         138532.076216   118430.910673   \n",
       "2          128478.197544         149772.500875    98025.493775   \n",
       "3          112995.017070         116435.661968    97396.407900   \n",
       "4          153034.168657         153558.656517   111143.027711   \n",
       "..                   ...                   ...             ...   \n",
       "287        263619.749227         246863.530560   193733.388149   \n",
       "288        180573.107057         170542.417567   137372.957888   \n",
       "289        132455.762402         139596.575508   106045.326993   \n",
       "290        108509.824907         112157.994953   102181.881757   \n",
       "291        283112.889525         234790.182070   189229.858057   \n",
       "\n",
       "     Actual_SalePrice  Mean_SalePrice  Weighted_Mean_SalePrice  \n",
       "0            208500.0   185337.112998            194026.451664  \n",
       "1            129500.0   129417.954594            132553.902928  \n",
       "2            132000.0   123556.856848            130936.639170  \n",
       "3             90000.0   108616.569688            112335.151209  \n",
       "4            159000.0   137715.126478            148369.132926  \n",
       "..                ...             ...                      ...  \n",
       "287          271000.0   232744.691390            250636.486400  \n",
       "288          192140.0   161731.858998            172715.650256  \n",
       "289          143750.0   125163.890023            131599.456900  \n",
       "290           64500.0   107536.954265            108935.115520  \n",
       "291          287090.0   232564.316481            257086.180190  \n",
       "\n",
       "[292 rows x 6 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check weighted mean on holdout set\n",
    "\n",
    "holdout_predictions_df.applymap(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop other columns\n",
    "decision_tree_predictions = decision_tree_predictions[[\"Id\",\"SalePrice\"]]\n",
    "\n",
    "# Create mean prediction submission CSV\n",
    "mean_predictions = decision_tree_predictions\n",
    "mean_predictions.to_csv(\"submission_mean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c22511",
   "metadata": {},
   "source": [
    "Taking the mean of predictions did not beat my score from just using LightGBM in the previous post.\n",
    "\n",
    "<img src=\"./mean_predictions_kaggle.png\" width=\"600\">\n",
    "\n",
    "Next, I'll try defining a meta-model to best blend predictions from the two models. After developing each model, predictions were also made on a holdout dataset that was kept separate from the training and validation datasets, for the explicit purpose of training this meta-model. The model trained on this dataset was then used to blend predictions on the test dataset to be submitted to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0349413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "test_predictions_dt = pd.read_csv(\"/root/data-science-projects-1/house-price-prediction/Models/sklearn/submission_dt.csv\")\n",
    "test_predictions_nn = pd.read_csv(\"/root/data-science-projects-1/house-price-prediction/Models/tensorflow/submission_nn.csv\")\n",
    "\n",
    "# Merge CSVs on Id column\n",
    "test_predictions_dt[\"NN_predictions\"] = test_predictions_nn[\"SalePrice\"]\n",
    "\n",
    "# Rename decision tree predictions column\n",
    "test_predictions_dt = test_predictions_dt.rename(columns={\"SalePrice\":\"DT_predictions\"})\n",
    "\n",
    "# Rename df\n",
    "blended_predictions_df = test_predictions_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76de3cc",
   "metadata": {},
   "source": [
    "The meta-model was a simple grid search across different estimators, without attempting to optimize hyperparameters. Since the holdout dataset is very small, I used 10 folds in the cross-validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88d80bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1495170648143068"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Int64Index.*\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Defining a custom loss function (Root Mean Squared Error)\n",
    "rmse = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "X = holdout_predictions_df[[\"XGBoost_Predictions\", \"LightGBM_Predictions\", \"NN_Predictions\"]]\n",
    "y = holdout_predictions_df[\"Actual_SalePrice\"]\n",
    "\n",
    "estimators = [\n",
    "    {\n",
    "        \"clf\": (LinearRegression(),)\n",
    "    },\n",
    "    {\n",
    "        \"clf\": (Ridge(),)\n",
    "    },\n",
    "    {\n",
    "        \"clf\": (xgb.XGBRegressor(),)\n",
    "    },\n",
    "    {\n",
    "       \"clf\": (lgb.LGBMRegressor(),)\n",
    "    }\n",
    "]\n",
    "\n",
    "pipe = Pipeline([(\"clf\", LinearRegression())])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, estimators, cv=20, scoring=rmse)\n",
    "grid_search.fit(X,y)\n",
    "grid_search.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57b6bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00156263, 0.00148139, 0.14347031, 0.04534595]),\n",
       " 'std_fit_time': array([0.00034978, 0.00024029, 0.1271254 , 0.08243149]),\n",
       " 'mean_score_time': array([0.0009854 , 0.00090621, 0.00396862, 0.00125448]),\n",
       " 'std_score_time': array([0.0001783 , 0.00012706, 0.00024219, 0.00014019]),\n",
       " 'param_clf': masked_array(data=[LinearRegression(), Ridge(),\n",
       "                    XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                 colsample_bynode=None, colsample_bytree=None,\n",
       "                                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                 importance_type=None, interaction_constraints=None,\n",
       "                                 learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                 n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                                 predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                                 validate_parameters=None, verbosity=None)                          ,\n",
       "                    LGBMRegressor()],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf': LinearRegression()},\n",
       "  {'clf': Ridge()},\n",
       "  {'clf': XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None,\n",
       "                enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                validate_parameters=None, verbosity=None)},\n",
       "  {'clf': LGBMRegressor()}],\n",
       " 'split0_test_score': array([0.124303  , 0.124303  , 0.14296886, 0.1167825 ]),\n",
       " 'split1_test_score': array([0.1454644 , 0.1454644 , 0.13030211, 0.14027297]),\n",
       " 'split2_test_score': array([0.12729133, 0.12729133, 0.14003204, 0.14394574]),\n",
       " 'split3_test_score': array([0.10934255, 0.10934255, 0.13653749, 0.11729312]),\n",
       " 'split4_test_score': array([0.09414177, 0.09414177, 0.12140953, 0.12922292]),\n",
       " 'split5_test_score': array([0.16133295, 0.16133295, 0.09267824, 0.11627213]),\n",
       " 'split6_test_score': array([0.22969164, 0.22969164, 0.19987408, 0.20247614]),\n",
       " 'split7_test_score': array([0.09884306, 0.09884306, 0.10961917, 0.08233112]),\n",
       " 'split8_test_score': array([0.18396428, 0.18396428, 0.16153212, 0.17262816]),\n",
       " 'split9_test_score': array([0.20168769, 0.20168769, 0.13983944, 0.16458661]),\n",
       " 'split10_test_score': array([0.1580367 , 0.1580367 , 0.15067488, 0.12445452]),\n",
       " 'split11_test_score': array([0.08894857, 0.08894857, 0.07055097, 0.10327954]),\n",
       " 'split12_test_score': array([0.13394331, 0.13394331, 0.12852996, 0.1748637 ]),\n",
       " 'split13_test_score': array([0.13324126, 0.13324126, 0.14830873, 0.13193407]),\n",
       " 'split14_test_score': array([0.1612218 , 0.1612218 , 0.11674397, 0.11752183]),\n",
       " 'split15_test_score': array([0.13441964, 0.13441964, 0.22888399, 0.21013224]),\n",
       " 'split16_test_score': array([0.11239019, 0.11239019, 0.19085294, 0.14863626]),\n",
       " 'split17_test_score': array([0.16085543, 0.16085543, 0.11612964, 0.11612001]),\n",
       " 'split18_test_score': array([0.18421213, 0.18421213, 0.17132999, 0.12419774]),\n",
       " 'split19_test_score': array([0.2036676 , 0.2036676 , 0.23574997, 0.20708987]),\n",
       " 'mean_test_score': array([0.14734996, 0.14734996, 0.14662741, 0.14220206]),\n",
       " 'std_test_score': array([0.0381005 , 0.0381005 , 0.04103491, 0.03481417]),\n",
       " 'rank_test_score': array([1, 2, 3, 4], dtype=int32)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f117f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "grid_search_blended_predictions = grid_search.predict(blended_predictions_df[[\"DT_predictions\", \"NN_predictions\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a154b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to a dataframe\n",
    "grid_search_blended_predictions_df = blended_predictions_df\n",
    "grid_search_blended_predictions_df[\"SalePrice\"] = grid_search_blended_predictions\n",
    "grid_search_blended_predictions_df = grid_search_blended_predictions_df.drop(columns=[\"DT_predictions\",\"NN_predictions\"])\n",
    "\n",
    "# Create CSV with blended predictions\n",
    "grid_search_blended_predictions_df.to_csv(\"submission_gridsearch_blended.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_blended_predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b1299",
   "metadata": {},
   "source": [
    "I had high hopes for a meta-model that blended predictions, but it performed worse than I expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3e2d2",
   "metadata": {},
   "source": [
    "## Improvements to subsequent models\n",
    "\n",
    "Below I note some improvements to the models I would implement if I had more time.\n",
    "\n",
    "- Remove outliers (using something like sklearn's IsolationForest)\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
